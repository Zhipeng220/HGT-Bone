# ==============================================================================
# 核心设置：断点续训与工作目录
# ==============================================================================
work_dir: ./work_dir/SHREC/bone

# [关键修改 1] 加载 Epoch 25 的最佳权重 (Top-1: 87.14%)
weights: ./work_dir/SHREC/bone/epoch025_acc87.14_model.pt

# [关键修改 2] 设置起始 Epoch (跳过 Warm-up)
# 系统将从第 26 个 Epoch 开始训练
start_epoch: 25

# 1. 训练流设置
stream: bone
phase: train  # 确保是训练模式

# ==============================================================================
# 2. 模型定义 (Softmax + Entropy 架构)
# ==============================================================================
model: net.dsa_hgn.Model
model_args:
  in_channels: 3
  base_channels: 64
  ch_ratio: 2
  num_stages: 10
  inflate_stages: [5, 8]
  down_stages: [5, 8]
  data_bn_type: 'VC'
  num_person: 1
  pretrained: None
  num_class: 14
  num_point: 22
  drop_out: 0.0
  graph: graph.shrec.Graph
  graph_args:
    labeling_mode: 'spatial'
  num_hyperedges: 16
  k_neighbors: 4       # (注：在 Softmax 模式下此参数不影响梯度，仅作为兼容性保留)
  adaptive: true
  use_virtual_conn: True

# ==============================================================================
# 3. 数据加载
# ==============================================================================
train_feeder: feeder.feeder_egogesture.Feeder
test_feeder: feeder.feeder_egogesture.Feeder

train_feeder_args:
  data_path: /Users/gzp/Desktop/exp/DATA/SHREC2017_data/train_data.npy
  label_path: /Users/gzp/Desktop/exp/DATA/SHREC2017_data/train_label.pkl
  split: train
  bone: True           # 开启 Bone 模式
  vel: False
  window_size: 180     # 长窗口
  normalization: False # 物理幅度保留
  random_choose: True
  random_move: False   # Bone 流通常不需要平移增强
  random_shift: True
  repeat: 5            # 数据重复采样
  debug: False
  use_mmap: True

test_feeder_args:
  data_path: /Users/gzp/Desktop/exp/DATA/SHREC2017_data/val_data.npy
  label_path: /Users/gzp/Desktop/exp/DATA/SHREC2017_data/val_label.pkl
  split: test
  bone: True
  vel: False
  window_size: 180
  normalization: False
  debug: False
  use_mmap: True

# ==============================================================================
# 4. 优化器与学习率调度 (关键策略调整)
# ==============================================================================
optimizer: SGD
base_lr: 0.05          # 初始学习率 (Epoch 26-29 将使用此值)
weight_decay: 0.0005
nesterov: True
grad_clip_norm: 1.0

# [关键修改 3] 激进的衰减策略
# Epoch 30: 0.05 -> 0.005 (消除震荡，冲击 88%+)
# Epoch 50: 0.005 -> 0.0005 (精细收敛)
step: [30, 50]

lr_decay_rate: 0.1
warm_up_epoch: 5       # (因 start_epoch=25，此设置在续训中会被忽略)
num_epoch: 150         # 总轮数，可根据收敛情况提前终止

# ==============================================================================
# 5. 硬件与 Batch
# ==============================================================================
device: [0]
batch_size: 32
test_batch_size: 32
num_worker: 4

# ==============================================================================
# 6. 损失函数 (软稀疏化配置)
# ==============================================================================
loss: torch.nn.CrossEntropyLoss

# 熵正则化权重
# 建议保持 0.001，若 Epoch 70 后准确率极高且仍想提高稀疏度，可微调至 0.005
lambda_entropy: 0.001
lambda_ortho: 0.1

# 日志设置
log_interval: 100
save_interval: 5
eval_interval: 5